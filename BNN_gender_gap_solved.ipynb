{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BNN_gender_gap.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNcprZDPf6SNUpk79qEXyoh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davide-ario/BNN/blob/main/BNN_gender_gap_solved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu6svriFEaJc"
      },
      "source": [
        "\n",
        "from warnings import filterwarnings\n",
        "import h5py\n",
        "#h5py.run_tests()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pymc3 as pm\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import make_moons\n",
        "#from scipy.special import comb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDhiFxHFEo9R"
      },
      "source": [
        "print(f\"Running on PyMC3 v{pm.__version__}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhjVsFe4Evzl"
      },
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "floatX = theano.config.floatX\n",
        "filterwarnings(\"ignore\")\n",
        "sns.set_style(\"white\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input data files are available in the \"../input/\" directory.\n",
        "import os\n",
        "print(\"Input files:\")\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "9YyjmRZT93Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "VDPVgaBQ_B6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "data = pd.read_csv(io.BytesIO(uploaded[\"wage_data_reduced.csv\"]),sep=\";\")\n",
        "data= data.loc[:, ~data.columns.isin(['fit'])]\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "data.info()\n",
        "print()\n",
        "print(data.shape)\n",
        "print(data.columns)\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "_D8oOYeJ_c5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = data.lnw\n",
        "X= data.loc[:, data.columns != \"lnw\"]"
      ],
      "metadata": {
        "id": "7NXMgISaETs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DftX62-BFGV1"
      },
      "source": [
        "X = X.astype(floatX)\n",
        "Y = Y.astype(floatX)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape\n"
      ],
      "metadata": {
        "id": "-b6i_VesGJ3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def construct_nnNEW(ann_input, ann_output):\n",
        "    n_hidden = 10\n",
        "\n",
        "    # Initialize random weights between each layer\n",
        "    init_1 = np.random.randn(X.shape[1], n_hidden).astype(floatX)\n",
        "    init_2 = np.random.randn(n_hidden, n_hidden).astype(floatX)\n",
        "    init_out = np.random.randn(n_hidden).astype(floatX)\n",
        "    init_b_1 = np.random.randn(n_hidden).astype(floatX)\n",
        "    init_b_2 = np.random.randn(n_hidden).astype(floatX)\n",
        "    init_b_3 = np.random.randn(n_hidden).astype(floatX)\n",
        "\n",
        "    init_b_out = np.random.randn(1).astype(floatX)\n",
        "\n",
        "#    init_1s = np.random.randn(X.shape[1], n_hidden).astype(floatX)\n",
        "#    init_2s = np.random.randn(n_hidden, n_hidden).astype(floatX)\n",
        "#    init_outs = np.random.randn(n_hidden).astype(floatX)\n",
        "#    init_b_1s = np.random.randn(n_hidden).astype(floatX)\n",
        "#    init_b_2s = np.random.randn(n_hidden).astype(floatX)\n",
        "#    init_b_3s = np.random.randn(n_hidden).astype(floatX)\n",
        "#\n",
        "#    init_b_outs = np.random.randn(1).astype(floatX)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    with pm.Model() as neural_network:\n",
        "        # Trick: Turn inputs and outputs into shared variables using the data container pm.Data\n",
        "        # It's still the same thing, but we can later change the values of the shared variable\n",
        "        # (to switch in the test-data later) and pymc3 will just use the new data.\n",
        "        # Kind-of like a pointer we can redirect.\n",
        "        # For more info, see: http://deeplearning.net/software/theano/library/compile/shared.html\n",
        "        ann_input = pm.Data(\"ann_input\", X_train)\n",
        "        ann_output = pm.Data(\"ann_output\", Y_train)\n",
        "        #here I can set shapes of err and errs equalt to (1)\n",
        "        err = pm.Normal(\"err\", 0, sigma=1, shape=(X_train.shape[0],))\n",
        "        errs = pm.Normal(\"errs\", 0, sigma=1, shape=(X_train.shape[0],))\n",
        "\n",
        "        model_sel=pm.Uniform('model_sel', lower=0, upper=1, shape=(X_train.shape[1],))\n",
        "#        delta = pm.HalfCauchy('delta', 1)\n",
        "        # Weights from input to hidden layer\n",
        "        weights_in_1 = pm.Normal(\"w_in_1\", 0, sigma=1, shape=(X.shape[1], n_hidden), testval=init_1)\n",
        "        bias1 = pm.Normal(\"bias1\", 0, sigma=1, shape=n_hidden, testval=init_b_1)\n",
        "\n",
        "        # Weights from 1st to 2nd layer\n",
        "        weights_1_2 = pm.Normal(\"w_1_2\", 0, sigma=1, shape=(n_hidden, n_hidden), testval=init_2)\n",
        "        bias2 = pm.Normal(\"bias2\", 0, sigma=1, shape=n_hidden, testval=init_b_2)\n",
        "\n",
        "#              # Weights from 1st to 2nd layer\n",
        "#        weights_1_2 = pm.Normal(\"w_2_2\", 0, sigma=1, shape=(n_hidden, n_hidden), testval=init_2)\n",
        "        # Weights from hidden layer to output\n",
        "        weights_2_2 = pm.Normal(\"w_2_2\", 0, sigma=1, shape=(n_hidden, n_hidden), testval=init_2)\n",
        "        bias3 = pm.Normal(\"bias3\", 0, sigma=1, shape=n_hidden, testval=init_b_3)\n",
        "\n",
        "        weights_2_out = pm.Normal(\"w_2_out\", 0, sigma=1, shape=(n_hidden,), testval=init_out)\n",
        "\n",
        "        # Build neural-network using tanh activation function\n",
        "#        mu_para= alpha + ann_input[:,0]*beta[0]+ann_input[:,1]*beta[1]\n",
        "        input_continuos = ann_input*(1-model_sel)\n",
        "        act_1 = T.nnet.relu(pm.math.dot(input_continuos, weights_in_1)+bias1)\n",
        "        act_2 = T.nnet.relu(pm.math.dot(act_1, weights_1_2)+bias2)\n",
        "        act_3 = T.nnet.relu(pm.math.dot(act_2, weights_2_2)+bias3)\n",
        "#        act_1 = T.dot(ann_input, weights_in_1)+err\n",
        "#        act_2 = T.dot(act_1, weights_1_2)+err\n",
        "#\n",
        "#        act_3 = T.dot(act_2, weights_2_2)+err\n",
        "\n",
        "#        # Build neural-network using tanh activation function\n",
        "\n",
        "#        act_1 = T.dot(ann_input, weights_in_1)\n",
        "#        act_2 = T.dot(act_1, weights_1_2)\n",
        "\n",
        "        act_out = T.dot(act_3, weights_2_out)+err\n",
        "\n",
        "\n",
        "#        errs = pm.Normal(\"errs\", 0, sigma=1, shape=(X_train.shape[0],))\n",
        "\n",
        "#        delta = pm.HalfCauchy('delta', 1)\n",
        "        # Weights from input to hidden layer\n",
        "        ##data to point\n",
        "        \n",
        "        ##\n",
        "        weights_in_1s = pm.Normal(\"w_in_1s\", 0, sigma=1, shape=(X.shape[1], n_hidden), testval=init_1)\n",
        "        bias1s = pm.Normal(\"bias1s\", 0, sigma=1, shape=n_hidden, testval=init_b_1)\n",
        "\n",
        "        # Weights from 1st to 2nd layer\n",
        "        weights_1_2s = pm.Normal(\"w_1_2s\", 0, sigma=1, shape=(n_hidden, n_hidden), testval=init_2)\n",
        "        bias2s = pm.Normal(\"bias2s\", 0, sigma=1, shape=n_hidden, testval=init_b_2)\n",
        "\n",
        "#              # Weights from 1st to 2nd layer\n",
        "#        weights_1_2 = pm.Normal(\"w_2_2\", 0, sigma=1, shape=(n_hidden, n_hidden), testval=init_2)\n",
        "        # Weights from hidden layer to output\n",
        "        weights_2_2s = pm.Normal(\"w_2_2s\", 0, sigma=1, shape=(n_hidden, n_hidden), testval=init_2)\n",
        "        bias3s = pm.Normal(\"bias3s\", 0, sigma=1, shape=n_hidden, testval=init_b_3)\n",
        "\n",
        "        weights_2_outs = pm.Normal(\"w_2_outs\", 0, sigma=1, shape=(n_hidden,), testval=init_out)\n",
        "\n",
        "        # Build neural-network using tanh activation function\n",
        "#        mu_para= alpha + ann_input[:,0]*beta[0]+ann_input[:,1]*beta[1]\n",
        "        input_discrete = ann_input*model_sel\n",
        "\n",
        "        act_1s = pm.math.tanh(pm.math.dot(input_discrete, weights_in_1s)+bias1s)\n",
        "        act_2s = pm.math.tanh(pm.math.dot(act_1s, weights_1_2s)+bias2s)\n",
        "        act_3s = pm.math.tanh(pm.math.dot(act_2s, weights_2_2s)+bias3s)\n",
        "#        act_1 = T.dot(ann_input, weights_in_1)+err\n",
        "#        act_2 = T.dot(act_1, weights_1_2)+err\n",
        "#\n",
        "#        act_3 = T.dot(act_2, weights_2_2)+err\n",
        "\n",
        "#        # Build neural-network using tanh activation function\n",
        "\n",
        "#        act_1 = T.dot(ann_input, weights_in_1)\n",
        "#        act_2 = T.dot(act_1, weights_1_2)\n",
        "\n",
        "        act_outs = pm.math.sigmoid(pm.math.dot(act_3s, weights_2_outs)+errs)\n",
        "\n",
        "        # Binary classification -> Bernoulli likelihood\n",
        "        out = pm.Normal(\n",
        "            \"out\", mu=act_out+act_outs,\n",
        "            sigma=1, #here i can set sigma = 0.001\n",
        "            observed=ann_output,\n",
        "            total_size=Y_train.shape[0],  # IMPORTANT for minibatches\n",
        "        )\n",
        "    return neural_network\n",
        "\n",
        "#https://discourse.pymc.io/t/bayesian-neural-network-no-convergence/3430/8 convergence problem"
      ],
      "metadata": {
        "id": "gmpHDHFnFptB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "njdlokQ2Hm5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7oWF6BeeUUo"
      },
      "source": [
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "# For neural nets with my GPU, RNN doesn't work without this in TF 2.0\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "#session = InteractiveSession(config=config)\n",
        "\n",
        "print()\n",
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU found')\n",
        "else:\n",
        "    print(\"No GPU found\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "THEANO_FLAGS=blas.ldflags=\"-L/usr/lib64/ -lblas\" ipython\n"
      ],
      "metadata": {
        "id": "LKRCdjUsJ5P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "minibatch_x = pm.Minibatch(X_train, batch_size=512)\n",
        "minibatch_y = pm.Minibatch(Y_train, batch_size=512)\n",
        "neural_network_minibatch = construct_nnNEW(minibatch_x, minibatch_y)\n",
        "with neural_network_minibatch:\n",
        "    approx = pm.fit(30000, method=pm.ADVI())\n",
        "    #inference = pm.adamax(learning_rate=0.1)\n",
        "    #approx = pm.fit(n=30000, method=inference)\n",
        "    #approx = pm.fit(45000, method=pm.NUTS())\n",
        "    #trace = pm.sample(3000, tune=1000)\n",
        "\n",
        "\n",
        "trace = approx.sample(draws=5000)\n",
        "\n",
        "#pm.summary(trace, varnames=[\"model_sel\"])\n",
        "#https://discourse.pymc.io/t/bayesian-neural-network-no-convergence/3430/8 convergence problem"
      ],
      "metadata": {
        "id": "yMW_YMFVG2k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Pu-fbYW30X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1paqH-_eU3uV"
      },
      "source": [
        "#plt.plot(-inference.hist, label=\"new ADVI\", alpha=0.3)\n",
        "plt.plot(approx.hist[41000:], label=\"old ADVI\", alpha=0.3)\n",
        "plt.legend()\n",
        "plt.ylabel(\"ELBO\")\n",
        "plt.xlabel(\"iteration\")\n",
        "\n",
        "plt.plot(-approx.hist[100:], label=\"new ADVI\", alpha=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trace = approx.sample(draws=5000)"
      ],
      "metadata": {
        "id": "AqbkAIxw8DM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqLMbgxOU5zw"
      },
      "source": [
        "\n",
        "pm.summary(trace, var_names=\"model_sel\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV14p9Z0a39p"
      },
      "source": [
        "    pm.set_data(new_data={\"ann_input\": X_train, \"ann_output\": Y_train}, model=neural_network_minibatch)\n",
        "    ppc = pm.sample_posterior_predictive(\n",
        "        trace, samples=500, progressbar=True, model=neural_network_minibatch, random_seed=132\n",
        "    )\n",
        "\n",
        "   \n",
        "    pred = ppc[\"out\"].mean(axis=0)\n",
        "    pred.mean(axis=0)\n",
        "    error = (Y_train-pred)\n",
        "    plt.plot(pred, Y_train)\n",
        "    square_error = (Y_train-pred)**2\n",
        "    error.mean(axis=0)\n",
        "    square_error.mean(axis=0)\n",
        "    Y_pred=pred\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)    \n",
        "x = range(Y_train.shape[0])\n",
        "ax1.scatter(x,Y_train, c='r', marker=\"o\", label='observed')\n",
        "ax1.scatter(x,pred, c='b', marker='x', label='pred')\n",
        "plt.legend(loc='upper left');\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G8bDvZjLpkIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "square_error.mean(axis=0)"
      ],
      "metadata": {
        "id": "YYNlWxZspwAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r26VUk99cQOv"
      },
      "source": [
        "Compute the marginal impact of independent variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c= np.ones(X_train.shape[1])  # np.array([1,0,1,1,1])\n",
        "c[0]=0\n",
        "Xcounter = X_train*c\n",
        "\n",
        "#Y = X[:,0]*3-6*X[:,1]*X[:,1]+8*X[:,1]+np.random.normal(0, .2, 1000)+2+latent\n",
        "Xcounter = Xcounter.astype(floatX)\n",
        "X_train\n",
        "Xcounter"
      ],
      "metadata": {
        "id": "76sJuihExnXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "PR4QQN2MK8qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm.set_data(new_data={\"ann_input\": X_train, \"ann_output\": Y_train}, model=neural_network_minibatch)\n",
        "ppc = pm.sample_posterior_predictive(trace, samples=500, progressbar=True, model=neural_network_minibatch, random_seed=132)"
      ],
      "metadata": {
        "id": "2gLz91IsCVZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "841sE-Fab6iy"
      },
      "source": [
        "#create counterfactual for training\n",
        "# I want to capture the impact of X[0]\n",
        "#c= np.ones(X_train.shape[1])  # np.array([1,0,1,1,1])\n",
        "#c[0]=0\n",
        "#Xcounter = X_train*c\n",
        "\n",
        "#Y = X[:,0]*3-6*X[:,1]*X[:,1]+8*X[:,1]+np.random.normal(0, .2, 1000)+2+latent\n",
        "#Xcounter = Xcounter.astype(floatX)\n",
        "\n",
        "pm.set_data(new_data={\"ann_input\": Xcounter, \"ann_output\": Y_train}, model=neural_network_minibatch)\n",
        "ppc_counter = pm.sample_posterior_predictive(\n",
        "    trace, samples=500, progressbar=True, model=neural_network_minibatch, random_seed=132\n",
        ")\n",
        "pred_counter = ppc_counter[\"out\"].mean(axis=0)\n",
        "pred_counter.mean(axis=0)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "gJVnollpyb33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "questo qua sotto da problemi, mi traSFORMA X_TRAIN..IN FEMALE = 1"
      ],
      "metadata": {
        "id": "ANWKb-o-sZKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtreated = X_train*1\n"
      ],
      "metadata": {
        "id": "7Ig0g8ZsylUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtreated.loc[Xtreated[\"female\"] == 0,\"female\"] = 1\n"
      ],
      "metadata": {
        "id": "6u88dBCDzLX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtreated"
      ],
      "metadata": {
        "id": "bz7vVr_gzLJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "phJFAR5AynwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "pm.set_data(new_data={\"ann_input\": Xtreated, \"ann_output\": Y_train}, model=neural_network_minibatch)\n",
        "ppc_treated = pm.sample_posterior_predictive(\n",
        "    trace, samples=500, progressbar=True, model=neural_network_minibatch, random_seed=132\n",
        ")\n",
        "pred_treated = ppc_treated[\"out\"].mean(axis=0)\n",
        "pred_treated.mean(axis=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KIa2DPixncrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "impact= ppc_treated['out'] - ppc_counter['out']\n",
        "Y_impact = impact.mean(axis=0)"
      ],
      "metadata": {
        "id": "dSz-L21Nn8IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_impact.mean())\n",
        "print(Y_impact.std())"
      ],
      "metadata": {
        "id": "k8Dx8GqJrnzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)    \n",
        "ax1.scatter(X_train[\"female\"],Y_impact, c='b', marker='x', label='pred')\n",
        "plt.legend(loc='upper left');\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LKqPPVIjrNFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OLS estimates\n"
      ],
      "metadata": {
        "id": "Pui1Y-1m8f8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#exclude collinear variable\n",
        "\n",
        "\n",
        "X_ols= X_train\n",
        "X_ols['const']=1\n",
        "X_ols= X_ols.loc[:, ~X_ols.columns.isin(['Pf20', 'Pf35', 'Pf35','Pf62','Pf94','Rm12'])]\n"
      ],
      "metadata": {
        "id": "PR7WfjOzw0g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.iolib.summary2 import summary_col\n",
        "\n",
        "\n",
        "reg1 = sm.OLS(endog=Y_train, exog=X_train, missing='drop')\n",
        "#reg1 = sm.OLS(endog=Y_train, exog=X_ols, missing='drop')\n",
        "type(reg1)\n"
      ],
      "metadata": {
        "id": "CAsJ_MvU9wnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = reg1.fit()\n",
        "type(results)"
      ],
      "metadata": {
        "id": "Ud8rkiCX_J8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results.summary())"
      ],
      "metadata": {
        "id": "SrXHDOIU_LfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_ols = results.predict()"
      ],
      "metadata": {
        "id": "bv2jZzx__sQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OLSsquare_error = (Y_train-Y_ols)**2\n",
        "OLSsquare_error.mean(axis=0)\n",
        "#square_error.mean(axis=0)\n"
      ],
      "metadata": {
        "id": "6JgncPrI_vLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)    \n",
        "x = range(Y_train.shape[0])\n",
        "ax1.scatter(x,Y_train, c='r', marker=\"o\", label='observed')\n",
        "ax1.scatter(x,Y_ols, c='b', marker='x', label='pred')\n",
        "plt.legend(loc='upper left');\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uXFVUjXFp5wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfz5KgbDeg9e"
      },
      "source": [
        "Nested Bayesian neural network with model selection. This BNN is made up by two different BNN. For each variable the BNN chose which model is more appropiate, applying a specific weight."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksMU1LoCkBxf"
      },
      "source": [
        "pm.summary(trace, var_names=[\"model_sel\"])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}